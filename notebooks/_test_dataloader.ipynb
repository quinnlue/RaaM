{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5424c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import random\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337e5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BucketBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, tokens_per_batch, bucket_sizes, shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        self.buckets = defaultdict(list)\n",
    "\n",
    "        for idx, (_, _, bucket) in enumerate(dataset.row_maps):\n",
    "            self.buckets[bucket].append(idx)\n",
    "\n",
    "        self.batches = []\n",
    "        for bucket, indices in self.buckets.items():\n",
    "            bs = tokens_per_batch // bucket_sizes[bucket]\n",
    "            for i in range(0, len(indices), bs):\n",
    "                self.batches.append(indices[i:i+bs])\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.batches)\n",
    "        yield from self.batches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70689da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CoTDataset(Dataset):\n",
    "    def __init__(self, data_root: str, batch_column: str = \"bucket\", data_column: str = \"seq\", ext=\".parquet\"):\n",
    "        self.data_root = data_root\n",
    "        self.ext = ext\n",
    "        self.batch_column = batch_column\n",
    "        self.data_column = data_column\n",
    "        self.file_paths = self.get_file_paths()\n",
    "        self.row_maps = []\n",
    "        self.file_data = []\n",
    "        self._build_row_maps()\n",
    "\n",
    "    def get_file_paths(self):\n",
    "        return sorted([f for f in os.listdir(self.data_root) if f.endswith(self.ext)])\n",
    "\n",
    "    def _build_row_maps(self):\n",
    "        \"\"\"Build mapping from global index to (file_idx, row_idx, bucket)\"\"\"\n",
    "        for file_idx, file_path in enumerate(self.file_paths):\n",
    "            full_path = os.path.join(self.data_root, file_path)\n",
    "            df = pd.read_parquet(full_path)\n",
    "            self.file_data.append(df)\n",
    "            for row_idx in range(len(df)):\n",
    "                bucket = df.iloc[row_idx][self.batch_column]\n",
    "                self.row_maps.append((file_idx, row_idx, bucket))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx, row_idx, _ = self.row_maps[idx]\n",
    "        row = self.file_data[file_idx].iloc[row_idx]\n",
    "        data = row[self.data_column]\n",
    "\n",
    "        if isinstance(data, np.ndarray):\n",
    "            return torch.from_numpy(data.copy())  # .copy() to make writable\n",
    "        elif isinstance(data, list):\n",
    "            return torch.tensor(data)\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.row_maps)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"CoTDataset(data_root={self.data_root}, ext={self.ext}, file_paths={self.file_paths}, len={len(self)})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1e9b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoTDataset(data_root=data/, ext=.parquet, file_paths=['pq_1.parquet', 'pq_2.parquet'], len=16000)\n",
      "Sample row_map entry: (0, 0, np.int64(2))\n"
     ]
    }
   ],
   "source": [
    "dataset = CoTDataset(\n",
    "    data_root=\"data/\",\n",
    "    batch_column=\"bucket\",\n",
    "    data_column=\"seq\",\n",
    "    ext=\".parquet\"\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "print(f\"Sample row_map entry: {dataset.row_maps[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 941\n"
     ]
    }
   ],
   "source": [
    "bucket_sizes = {0: 16, 1: 32, 2: 64, 3: 128}\n",
    "if __name__ == \"__main__\":\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_sampler=BucketBatchSampler(\n",
    "            dataset,\n",
    "            tokens_per_batch=1024,\n",
    "            bucket_sizes=bucket_sizes,\n",
    "            shuffle=True\n",
    "\n",
    "        ),\n",
    "        num_workers=1,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Number of batches: {len(loader)}\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Test iterating over the dataloader\n",
    "    for i, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        print(f\"Batch {i}: shape={batch.shape}, dtype={batch.dtype}\")\n",
    "        if i >= 20:  # Just show first few batches\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e1b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ed06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115abd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
